{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnuGd7paintl"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-__k4l1lKXk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, confusion_matrix, classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bACVW2OlUcp"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import xgboost as xgb\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    HAS_SMOTE = True\n",
        "except Exception:\n",
        "    HAS_SMOTE = False\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    HAS_SHAP = True\n",
        "except Exception:\n",
        "    HAS_SHAP = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1mB8bH0lYbE"
      },
      "outputs": [],
      "source": [
        "CSV_PATH = \"rwsi_data.csv\"\n",
        "XLSX_PATH = \"RWSI.xlsx\"\n",
        "OUTPUT_DIR = Path(\"rwsi_full_outputs\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWPbJ4B6lZEd"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "CV_FOLDS = 5\n",
        "LOW_CARDINALITY_THRESHOLD = 20\n",
        "USE_SMOTE = False\n",
        "CLASS_WEIGHT_BALANCED = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMD6EBzFlbFl"
      },
      "outputs": [],
      "source": [
        "report_lines = []\n",
        "def write_report_line(s=\"\"):\n",
        "    print(s)\n",
        "    report_lines.append(str(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoQ1JiRXldNj",
        "outputId": "1d5bf62c-b9f8-4dfd-9f3e-4b6a89d9ddfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Loading files ====\n",
            "Loaded CSV: rwsi_data.csv shape=(12330, 20)\n",
            "Excel file not found; proceeding with heuristics.\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"==== Loading files ====\")\n",
        "xlsx_path = Path(XLSX_PATH)\n",
        "csv_path = Path(CSV_PATH)\n",
        "if not csv_path.exists():\n",
        "    raise FileNotFoundError(f\"CSV not found at {csv_path}\")\n",
        "df = pd.read_csv(csv_path)\n",
        "write_report_line(f\"Loaded CSV: {csv_path} shape={df.shape}\")\n",
        "\n",
        "detected_target = None\n",
        "if xlsx_path.exists():\n",
        "    try:\n",
        "        xls = pd.ExcelFile(xlsx_path)\n",
        "        write_report_line(f\"Loaded Excel: {xlsx_path} sheets={xls.sheet_names}\")\n",
        "\n",
        "        sheet_text = \"\"\n",
        "        for name in xls.sheet_names:\n",
        "            sheet_df = xls.parse(name, nrows=400).fillna(\"\").astype(str)\n",
        "            rows_joined = sheet_df.agg(' '.join, axis=1).tolist()\n",
        "            sheet_text += \" \" + \" \".join(rows_joined).lower()\n",
        "\n",
        "        import re\n",
        "        m = re.search(r\"(monetaryconversion|monetary conversion|target variable|target)\\s*(?:[:\\-]|\\s)\\s*([a-zA-Z0-9_]+)?\", sheet_text)\n",
        "\n",
        "        if \"monetaryconversion\" in sheet_text.replace(\" \", \"\") or \"monetary conversion\" in sheet_text:\n",
        "\n",
        "            if \"MonetaryConversion\" in df.columns:\n",
        "                detected_target = \"MonetaryConversion\"\n",
        "                write_report_line(\"Detected target from Excel text: MonetaryConversion\")\n",
        "\n",
        "        if detected_target is None and m and m.group(2):\n",
        "            cand = m.group(2)\n",
        "            if cand in df.columns:\n",
        "                detected_target = cand\n",
        "                write_report_line(f\"Detected target from Excel regex: {cand}\")\n",
        "    except Exception as e:\n",
        "        write_report_line(\"Failed to parse Excel for instructions: \" + repr(e))\n",
        "else:\n",
        "    write_report_line(\"Excel file not found; proceeding with heuristics.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I44jSUXSlio9",
        "outputId": "09407521-e26f-414a-ba4a-1581748dabb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Heuristic selected target: MonetaryConversion\n"
          ]
        }
      ],
      "source": [
        "if detected_target is None:\n",
        "\n",
        "    candidates = [\"MonetaryConversion\", \"monetaryconversion\", \"Monetary_Conversion\", \"conversion\", \"Conversion\", \"target\", \"label\", \"y\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            detected_target = c\n",
        "            write_report_line(f\"Heuristic selected target: {detected_target}\")\n",
        "            break\n",
        "if detected_target is None:\n",
        "\n",
        "    detected_target = df.columns[-1]\n",
        "    write_report_line(f\"No explicit target found; falling back to last column: {detected_target}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWviX3Uxljf6",
        "outputId": "5d600e02-0136-4a9c-8d27-62e671f9a2cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Quick EDA ====\n",
            "Columns (20): ['SessionID', 'AdClicks', 'InfoSectionCount', 'InfoSectionTime', 'HelpPageVisits', 'HelpPageTime', 'ItemBrowseCount', 'ItemBrowseTime', 'ExitRateFirstPage', 'SessionExitRatio', 'PageEngagementScore', 'HolidayProximityIndex', 'VisitMonth', 'UserPlatformID', 'WebClientCode', 'MarketZone', 'TrafficSourceCode', 'UserCategory', 'IsWeekendVisit', 'MonetaryConversion']\n",
            "Dataset shape: (12330, 20)\n",
            "Target column chosen: MonetaryConversion\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Quick EDA ====\")\n",
        "write_report_line(f\"Columns ({len(df.columns)}): {df.columns.tolist()}\")\n",
        "write_report_line(f\"Dataset shape: {df.shape}\")\n",
        "write_report_line(f\"Target column chosen: {detected_target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh37cZPPllg0",
        "outputId": "dc1303fc-e18d-4f60-805a-d7ace737191d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target value counts:\n",
            "{'No': 10422, 'Yes': 1908}\n"
          ]
        }
      ],
      "source": [
        "if detected_target in df.columns:\n",
        "    targ_counts = df[detected_target].value_counts(dropna=False)\n",
        "    write_report_line(f\"Target value counts:\\n{targ_counts.to_dict()}\")\n",
        "else:\n",
        "    raise KeyError(f\"Target column {detected_target} not present in CSV\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee3ceYk4lnfp",
        "outputId": "f54e73e5-45d6-4c77-d0fa-c1c2a0b4bb97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Preprocessing & feature engineering ====\n",
            "After dropping empty columns: (12330, 20)\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Preprocessing & feature engineering ====\")\n",
        "\n",
        "df = df.loc[:, ~df.isna().all()]\n",
        "write_report_line(f\"After dropping empty columns: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni_iWUzflptj"
      },
      "outputs": [],
      "source": [
        "datetime_cols = []\n",
        "for col in df.columns:\n",
        "    if \"date\" in col.lower() or \"time\" in col.lower() and df[col].dtype == object:\n",
        "        parsed = pd.to_datetime(df[col], errors=\"coerce\")\n",
        "        if parsed.notna().sum() > 0:\n",
        "            df[col + \"_parsed\"] = parsed\n",
        "            datetime_cols.append(col + \"_parsed\")\n",
        "            write_report_line(f\"Parsed {col} -> {col+'_parsed'} (parsed count {parsed.notna().sum()})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg-ySjVklr-n"
      },
      "outputs": [],
      "source": [
        "for col in df.select_dtypes(include=[\"datetime64[ns]\", \"datetime64\"]).columns.tolist():\n",
        "    if col not in datetime_cols:\n",
        "        datetime_cols.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgguf4LUluE_"
      },
      "outputs": [],
      "source": [
        "for dcol in list(dict.fromkeys(datetime_cols)):\n",
        "    try:\n",
        "        df[dcol] = pd.to_datetime(df[dcol], errors=\"coerce\")\n",
        "        df[f\"{dcol}_year\"] = df[dcol].dt.year\n",
        "        df[f\"{dcol}_month\"] = df[dcol].dt.month\n",
        "        df[f\"{dcol}_day\"] = df[dcol].dt.day\n",
        "        df[f\"{dcol}_weekday\"] = df[dcol].dt.weekday\n",
        "        df[f\"{dcol}_dayofyear\"] = df[dcol].dt.dayofyear\n",
        "\n",
        "        try:\n",
        "            df[f\"{dcol}_unix\"] = df[dcol].astype(\"int64\") // 10**9\n",
        "        except Exception:\n",
        "            df[f\"{dcol}_unix\"] = pd.to_numeric(df[dcol].view(\"int64\"), errors=\"coerce\") // 10**9\n",
        "        df.drop(columns=[dcol], inplace=True)\n",
        "        write_report_line(f\"Converted datetime column {dcol} into numeric features\")\n",
        "    except Exception as e:\n",
        "        write_report_line(f\"Datetime conversion failed for {dcol}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qALWuvyZlwRF",
        "outputId": "26d51d36-3a9a-439b-cf4f-c5af84b3e44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After dropping rows with missing target: (12330, 20)\n"
          ]
        }
      ],
      "source": [
        "df = df[~df[detected_target].isna()].reset_index(drop=True)\n",
        "write_report_line(f\"After dropping rows with missing target: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4GpJfNulyTl"
      },
      "outputs": [],
      "source": [
        "y_raw = df[detected_target].copy()\n",
        "X = df.drop(columns=[detected_target]).copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7lw7z4Il1DU",
        "outputId": "35f31329-9dbc-4e6a-ba9c-197878f744e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem type: Classification\n"
          ]
        }
      ],
      "source": [
        "y = y_raw\n",
        "if y.dtype == object:\n",
        "    y_num = pd.to_numeric(y, errors=\"coerce\")\n",
        "    if y_num.notna().sum() / len(y) > 0.5:\n",
        "        y = y_num\n",
        "        write_report_line(\"Converted majority of target values to numeric; treating as numeric.\")\n",
        "is_regression = False\n",
        "if pd.api.types.is_numeric_dtype(y) and y.nunique() > 20:\n",
        "    is_regression = True\n",
        "write_report_line(\"Problem type: \" + (\"Regression\" if is_regression else \"Classification\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGdl7DQDl3bb",
        "outputId": "f8ea754b-a1f6-485d-f91a-ae64d360d566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label mapping: {0: 'No', 1: 'Yes'}\n"
          ]
        }
      ],
      "source": [
        "label_encoder = None\n",
        "if not is_regression:\n",
        "    if not pd.api.types.is_numeric_dtype(y):\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_enc = label_encoder.fit_transform(y.astype(str))\n",
        "        write_report_line(f\"Label mapping: {dict(enumerate(label_encoder.classes_))}\")\n",
        "    else:\n",
        "        y_enc = y.astype(int).values\n",
        "else:\n",
        "    y_enc = y.astype(float).values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4-NsfzEl6Ah"
      },
      "outputs": [],
      "source": [
        "bool_cols = [c for c in X.columns if X[c].dtype == \"bool\"]\n",
        "for c in bool_cols:\n",
        "    X[c] = X[c].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2sILkv5l-Qr",
        "outputId": "c6c4e23c-7785-4d06-f084-26adb4c4ccbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric columns (13): ['AdClicks', 'InfoSectionCount', 'InfoSectionTime', 'HelpPageVisits', 'HelpPageTime', 'ItemBrowseCount', 'ItemBrowseTime', 'ExitRateFirstPage', 'SessionExitRatio', 'PageEngagementScore', 'HolidayProximityIndex', 'TrafficSourceCode', 'IsWeekendVisit']\n",
            "Categorical columns (6): ['SessionID', 'VisitMonth', 'UserPlatformID', 'WebClientCode', 'MarketZone', 'UserCategory']\n",
            "Low-card categorical: ['VisitMonth', 'UserPlatformID', 'WebClientCode', 'MarketZone', 'UserCategory']\n",
            "High-card categorical: ['SessionID']\n"
          ]
        }
      ],
      "source": [
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "write_report_line(f\"Numeric columns ({len(numeric_cols)}): {numeric_cols}\")\n",
        "write_report_line(f\"Categorical columns ({len(cat_cols)}): {cat_cols}\")\n",
        "\n",
        "low_card = [c for c in cat_cols if X[c].nunique(dropna=False) <= LOW_CARDINALITY_THRESHOLD]\n",
        "high_card = [c for c in cat_cols if X[c].nunique(dropna=False) > LOW_CARDINALITY_THRESHOLD]\n",
        "write_report_line(f\"Low-card categorical: {low_card}\")\n",
        "write_report_line(f\"High-card categorical: {high_card}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6CV0Y7JmAmK"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "sk_ver = tuple(int(x) for x in sklearn.__version__.split('.')[:2])\n",
        "ohe_kwargs = {}\n",
        "if sk_ver >= (1, 2):\n",
        "\n",
        "    ohe_kwargs['sparse_output'] = False\n",
        "else:\n",
        "    ohe_kwargs['sparse'] = False\n",
        "\n",
        "num_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
        "cat_low_transformer = None\n",
        "if low_card:\n",
        "    cat_low_transformer = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", **ohe_kwargs))\n",
        "    ])\n",
        "cat_high_transformer = None\n",
        "if high_card:\n",
        "    cat_high_transformer = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ordinal\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "    ])\n",
        "\n",
        "transformers = []\n",
        "if numeric_cols:\n",
        "    transformers.append((\"num\", num_transformer, numeric_cols))\n",
        "if low_card:\n",
        "    transformers.append((\"cat_low\", cat_low_transformer, low_card))\n",
        "if high_card:\n",
        "    transformers.append((\"cat_high\", cat_high_transformer, high_card))\n",
        "preprocessor = ColumnTransformer(transformers=transformers, remainder=\"drop\", sparse_threshold=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z8hlzMPmC_h",
        "outputId": "9148e288-31bc-434d-f0aa-9d671bb3dbcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/test shapes: (9864, 19), (2466, 19)\n"
          ]
        }
      ],
      "source": [
        "if not is_regression:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_enc)\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "\n",
        "write_report_line(f\"Train/test shapes: {X_train.shape}, {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN4pWUwCmDmF"
      },
      "outputs": [],
      "source": [
        "if USE_SMOTE and (not is_regression) and HAS_SMOTE:\n",
        "    write_report_line(\"Applying SMOTE on training set to handle class imbalance (USE_SMOTE=True)\")\n",
        "    sm = SMOTE(random_state=RANDOM_STATE)\n",
        "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "    X_train, y_train = X_train_res, y_train_res\n",
        "    write_report_line(f\"After SMOTE train shape: {X_train.shape}\")\n",
        "elif USE_SMOTE and not HAS_SMOTE:\n",
        "    write_report_line(\"USE_SMOTE requested but imblearn not installed. Skipping SMOTE.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg9QMtpbmGHB",
        "outputId": "4ef4b0b6-6f80-4546-91f1-18a321929b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Model definitions ====\n",
            "Models to train: ['LogisticRegression', 'DecisionTree', 'RandomForest', 'NaiveBayes', 'SVC', 'XGBoost']\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Model definitions ====\")\n",
        "models = {}\n",
        "\n",
        "if not is_regression:\n",
        "    lr_kwargs = {\"max_iter\": 2000}\n",
        "    dt_kwargs = {\"random_state\": RANDOM_STATE}\n",
        "    rf_kwargs = {\"n_estimators\": 200, \"random_state\": RANDOM_STATE, \"n_jobs\": 1}\n",
        "    if CLASS_WEIGHT_BALANCED:\n",
        "        lr_kwargs[\"class_weight\"] = \"balanced\"\n",
        "        dt_kwargs[\"class_weight\"] = \"balanced\"\n",
        "        rf_kwargs[\"class_weight\"] = \"balanced\"\n",
        "    models[\"LogisticRegression\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", LogisticRegression(**lr_kwargs))])\n",
        "    models[\"DecisionTree\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", DecisionTreeClassifier(**dt_kwargs))])\n",
        "    models[\"RandomForest\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", RandomForestClassifier(**rf_kwargs))])\n",
        "    models[\"NaiveBayes\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", GaussianNB())])\n",
        "    models[\"SVC\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", SVC(probability=True, random_state=RANDOM_STATE))])\n",
        "    if HAS_XGB:\n",
        "        models[\"XGBoost\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE))])\n",
        "else:\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    models[\"LinearRegression\"] = Pipeline([(\"pre\", preprocessor), (\"reg\", LinearRegression())])\n",
        "    models[\"DecisionTreeRegressor\"] = Pipeline([(\"pre\", preprocessor), (\"reg\", DecisionTreeRegressor(random_state=RANDOM_STATE))])\n",
        "    models[\"RandomForestRegressor\"] = Pipeline([(\"pre\", preprocessor), (\"reg\", RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE))])\n",
        "    if HAS_XGB:\n",
        "        models[\"XGBoostRegressor\"] = Pipeline([(\"pre\", preprocessor), (\"reg\", xgb.XGBRegressor(random_state=RANDOM_STATE))])\n",
        "\n",
        "write_report_line(f\"Models to train: {list(models.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ESI6-FtmIfH",
        "outputId": "e6ac5f8a-b213-46fe-8a8a-0263cea410ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Training & evaluation ====\n",
            "\n",
            "-- Training LogisticRegression ...\n",
            "LogisticRegression metrics -> Acc: 0.8788, Precision (macro): 0.8110, Recall (macro): 0.6599, F1 (macro): 0.6993, ROC-AUC: None\n",
            "LogisticRegression CV (f1_macro) mean ± std: 0.7140 ± 0.0145\n",
            "Saved pipeline to: rwsi_full_outputs/LogisticRegression.joblib\n",
            "\n",
            "-- Training DecisionTree ...\n",
            "DecisionTree metrics -> Acc: 0.7936, Precision (macro): 0.6497, Recall (macro): 0.7004, F1 (macro): 0.6658, ROC-AUC: None\n",
            "DecisionTree CV (f1_macro) mean ± std: 0.6705 ± 0.0241\n",
            "Saved pipeline to: rwsi_full_outputs/DecisionTree.joblib\n",
            "\n",
            "-- Training RandomForest ...\n",
            "RandomForest metrics -> Acc: 0.8990, Precision (macro): 0.8354, Recall (macro): 0.7425, F1 (macro): 0.7773, ROC-AUC: None\n",
            "RandomForest CV (f1_macro) mean ± std: 0.7871 ± 0.0069\n",
            "Saved pipeline to: rwsi_full_outputs/RandomForest.joblib\n",
            "\n",
            "-- Training NaiveBayes ...\n",
            "NaiveBayes metrics -> Acc: 0.7174, Precision (macro): 0.6260, Recall (macro): 0.7195, F1 (macro): 0.6264, ROC-AUC: None\n",
            "NaiveBayes CV (f1_macro) mean ± std: 0.6468 ± 0.0154\n",
            "Saved pipeline to: rwsi_full_outputs/NaiveBayes.joblib\n",
            "\n",
            "-- Training SVC ...\n",
            "SVC metrics -> Acc: 0.8451, Precision (macro): 0.4225, Recall (macro): 0.5000, F1 (macro): 0.4580, ROC-AUC: None\n",
            "SVC CV (f1_macro) mean ± std: 0.4581 ± 0.0023\n",
            "Saved pipeline to: rwsi_full_outputs/SVC.joblib\n",
            "\n",
            "-- Training XGBoost ...\n",
            "XGBoost metrics -> Acc: 0.8885, Precision (macro): 0.7948, Recall (macro): 0.7523, F1 (macro): 0.7708, ROC-AUC: None\n",
            "XGBoost CV (f1_macro) mean ± std: 0.7592 ± 0.0197\n",
            "Saved pipeline to: rwsi_full_outputs/XGBoost.joblib\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Training & evaluation ====\")\n",
        "results = {}\n",
        "for name, pipe in models.items():\n",
        "    try:\n",
        "        write_report_line(f\"\\n-- Training {name} ...\")\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        y_proba = None\n",
        "        if not is_regression:\n",
        "            try:\n",
        "                clf = pipe.named_steps[list(pipe.named_steps.keys())[-1]]\n",
        "                if hasattr(clf, \"predict_proba\"):\n",
        "                    y_proba = clf.predict_proba(pipe.named_steps[\"pre\"].transform(X_test) if False else pipe.predict_proba if False else pipe.predict_proba)\n",
        "\n",
        "                    y_proba = pipe.predict_proba(X_test)\n",
        "            except Exception:\n",
        "                y_proba = None\n",
        "\n",
        "        if not is_regression:\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "            rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "            f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "            try:\n",
        "                if y_proba is not None:\n",
        "                    if y_proba.shape[1] == 2:\n",
        "                        roc = roc_auc_score(y_test, y_proba[:, 1])\n",
        "                    else:\n",
        "                        roc = roc_auc_score(pd.get_dummies(y_test), y_proba, average=\"macro\")\n",
        "                else:\n",
        "                    roc = None\n",
        "            except Exception:\n",
        "                roc = None\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            results[name] = {\"accuracy\": float(acc), \"precision_macro\": float(prec), \"recall_macro\": float(rec), \"f1_macro\": float(f1), \"roc_auc\": float(roc) if roc is not None else None, \"confusion_matrix\": cm.tolist()}\n",
        "            write_report_line(f\"{name} metrics -> Acc: {acc:.4f}, Precision (macro): {prec:.4f}, Recall (macro): {rec:.4f}, F1 (macro): {f1:.4f}, ROC-AUC: {roc}\")\n",
        "        else:\n",
        "\n",
        "            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "            mse = mean_squared_error(y_test, y_pred); rmse = np.sqrt(mse); mae = mean_absolute_error(y_test, y_pred); r2 = r2_score(y_test, y_pred)\n",
        "            results[name] = {\"rmse\": float(rmse), \"mae\": float(mae), \"r2\": float(r2)}\n",
        "            write_report_line(f\"{name} metrics -> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            if not is_regression:\n",
        "\n",
        "                scoring = \"f1_macro\"\n",
        "                cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "                cv_scores = cross_val_score(pipe, X, y_enc if not is_regression else y, scoring=scoring, cv=cv, n_jobs=1)\n",
        "                write_report_line(f\"{name} CV ({scoring}) mean ± std: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "                results[name][\"cv_\"+scoring] = float(cv_scores.mean())\n",
        "            else:\n",
        "                cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "                neg_mse = cross_val_score(pipe, X, y, scoring=\"neg_mean_squared_error\", cv=cv, n_jobs=1)\n",
        "                cv_rmse = np.sqrt(-neg_mse)\n",
        "                write_report_line(f\"{name} CV RMSE mean ± std: {cv_rmse.mean():.4f} ± {cv_rmse.std():.4f}\")\n",
        "                results[name][\"cv_rmse_mean\"] = float(cv_rmse.mean())\n",
        "        except Exception as e:\n",
        "            write_report_line(f\"Cross-validation failed for {name}: {e}\")\n",
        "            results[name][\"cv_error\"] = str(e)\n",
        "\n",
        "        model_path = OUTPUT_DIR / f\"{name}.joblib\"\n",
        "        joblib.dump(pipe, model_path)\n",
        "        write_report_line(f\"Saved pipeline to: {model_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        write_report_line(f\"Training failed for {name}: {repr(e)}\")\n",
        "        write_report_line(traceback.format_exc())\n",
        "        results[name] = {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "daWAQAG7mMnK",
        "outputId": "7b66ccd9-d19e-4ce5-fe0d-1aacac546580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Feature importances (tree models) ====\n",
            "DecisionTree top features: [('PageEngagementScore', 0.41218393736379244), ('SessionExitRatio', 0.068517975531233), ('SessionID', 0.06826503019226485), ('ItemBrowseTime', 0.06474474503844489), ('ExitRateFirstPage', 0.05995865675188367), ('ItemBrowseCount', 0.050620335277355), ('InfoSectionTime', 0.04447332683315313), ('InfoSectionCount', 0.03419893011514298), ('VisitMonth_November', 0.019962064287095797), ('HelpPageTime', 0.018804226474127817), ('TrafficSourceCode', 0.01751812542441936), ('AdClicks', 0.01470519790204845), ('HelpPageVisits', 0.011183121949028832), ('MarketZone_North America', 0.007351915519834998), ('VisitMonth_March', 0.006861964114417008), ('MarketZone_Other', 0.006738687201029202), ('IsWeekendVisit', 0.005799569893359543), ('MarketZone_Asia-Pacific', 0.0056211766553364555), ('UserCategory_Returning', 0.005289259396823774), ('UserPlatformID_MacOS', 0.005282900497130034)]\n",
            "RandomForest top features: [('PageEngagementScore', 0.32187821544947665), ('SessionExitRatio', 0.07592598847764148), ('ItemBrowseTime', 0.07201602036796285), ('ItemBrowseCount', 0.06214856250794876), ('SessionID', 0.056621492429017845), ('InfoSectionTime', 0.05104857459376629), ('ExitRateFirstPage', 0.0502367395694744), ('InfoSectionCount', 0.038892783755486826), ('TrafficSourceCode', 0.02704302188162953), ('AdClicks', 0.025558373842529084), ('HelpPageTime', 0.02327303221767748), ('VisitMonth_November', 0.018280449755819744), ('HelpPageVisits', 0.01692869566830404), ('MarketZone_North America', 0.009760088278044216), ('IsWeekendVisit', 0.009589499711689436), ('UserPlatformID_Android', 0.00784829034092484), ('WebClientCode_Chrome', 0.007835387313514956), ('MarketZone_Asia-Pacific', 0.007744709387720823), ('UserCategory_Returning', 0.007702081699202021), ('UserCategory_New', 0.007378710675689157)]\n",
            "XGBoost top features: [('PageEngagementScore', 0.18361078202724457), ('VisitMonth_November', 0.07701026648283005), ('VisitMonth_May', 0.045880042016506195), ('VisitMonth_March', 0.038380078971385956), ('UserCategory_Returning', 0.02883128449320793), ('InfoSectionCount', 0.027620352804660797), ('VisitMonth_September', 0.024802573025226593), ('ExitRateFirstPage', 0.02471223473548889), ('MarketZone_Other', 0.02375989779829979), ('MarketZone_Central America', 0.01881660893559456), ('UserCategory_New', 0.017834220081567764), ('MarketZone_Middle East', 0.017360001802444458), ('VisitMonth_July', 0.017162231728434563), ('ItemBrowseCount', 0.01714201457798481), ('UserPlatformID_Windows', 0.016944188624620438), ('ItemBrowseTime', 0.01654602773487568), ('SessionExitRatio', 0.016260502859950066), ('WebClientCode_Safari', 0.01619829796254635), ('VisitMonth_December', 0.01598854549229145), ('MarketZone_Asia-Pacific', 0.015346269123256207)]\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Feature importances (tree models) ====\")\n",
        "for name in models:\n",
        "    if \"DecisionTree\" in name or \"RandomForest\" in name or (\"XGBoost\" in name and HAS_XGB):\n",
        "        try:\n",
        "            pipe = joblib.load(OUTPUT_DIR / f\"{name}.joblib\")\n",
        "            pre = pipe.named_steps[\"pre\"]\n",
        "            feature_names = []\n",
        "            for tname, trans, cols in pre.transformers_:\n",
        "                if tname == \"num\":\n",
        "                    feature_names.extend(cols)\n",
        "                elif tname == \"cat_low\":\n",
        "                    ohe = trans.named_steps[\"onehot\"]\n",
        "                    names = ohe.get_feature_names_out(cols).tolist()\n",
        "                    feature_names.extend(names)\n",
        "                elif tname == \"cat_high\":\n",
        "                    feature_names.extend(cols)\n",
        "            last_step = list(pipe.named_steps.keys())[-1]\n",
        "            model_obj = pipe.named_steps[last_step]\n",
        "            if hasattr(model_obj, \"feature_importances_\"):\n",
        "                importances = model_obj.feature_importances_\n",
        "                idx = np.argsort(importances)[::-1][:30]\n",
        "                fi = [(feature_names[i] if i < len(feature_names) else f\"f{i}\", float(importances[i])) for i in idx]\n",
        "                write_report_line(f\"{name} top features: {fi[:20]}\")\n",
        "                results[name][\"feature_importances\"] = fi\n",
        "            else:\n",
        "                write_report_line(f\"{name} model has no feature_importances_ attribute\")\n",
        "        except Exception as e:\n",
        "            write_report_line(f\"Failed to extract importances for {name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HjR6CWg2mPGz",
        "outputId": "4866feb0-b976-43d2-fce3-69dacdfe5f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== SHAP explanation for RandomForest (top 20) ====\n",
            "SHAP summarization failed: only integer scalar arrays can be converted to a scalar index\n"
          ]
        }
      ],
      "source": [
        "if HAS_SHAP and \"RandomForest\" in models:\n",
        "    try:\n",
        "        write_report_line(\"\\n==== SHAP explanation for RandomForest (top 20) ====\")\n",
        "        rf_pipe = joblib.load(OUTPUT_DIR / \"RandomForest.joblib\")\n",
        "\n",
        "        X_pre = preprocessor.fit_transform(X) if False else None\n",
        "        X_sample = X.sample(n=min(200, len(X)), random_state=RANDOM_STATE)\n",
        "        X_trans = rf_pipe.named_steps[\"pre\"].transform(X_sample)\n",
        "        model_rf = rf_pipe.named_steps[\"clf\"]\n",
        "        explainer = shap.TreeExplainer(model_rf)\n",
        "        shap_values = explainer.shap_values(X_trans)\n",
        "\n",
        "        try:\n",
        "            if isinstance(shap_values, list):\n",
        "\n",
        "                mean_abs = np.mean([np.abs(sv).mean(0) for sv in shap_values], axis=0)\n",
        "            else:\n",
        "                mean_abs = np.abs(shap_values).mean(0)\n",
        "\n",
        "            feat_names = []\n",
        "            for tname, trans, cols in rf_pipe.named_steps[\"pre\"].transformers_:\n",
        "                if tname == \"num\":\n",
        "                    feat_names.extend(cols)\n",
        "                elif tname == \"cat_low\":\n",
        "                    ohe = trans.named_steps[\"onehot\"]\n",
        "                    feat_names.extend(ohe.get_feature_names_out(cols).tolist())\n",
        "                elif tname == \"cat_high\":\n",
        "                    feat_names.extend(cols)\n",
        "            idx = np.argsort(mean_abs)[::-1][:20]\n",
        "            shap_top = [(feat_names[i], float(mean_abs[i])) for i in idx]\n",
        "            write_report_line(f\"SHAP top features (RandomForest): {shap_top}\")\n",
        "            results[\"RandomForest\"][\"shap_top20\"] = shap_top\n",
        "        except Exception as e:\n",
        "            write_report_line(\"SHAP summarization failed: \" + str(e))\n",
        "    except Exception as e:\n",
        "        write_report_line(\"SHAP step failed: \" + str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CPv-GJV8mRgc",
        "outputId": "c073dfa8-4db5-489f-dfe3-82d71dce5fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Saving report & artifacts ====\n",
            "Report written to: rwsi_full_outputs/rwsi_full_report.txt\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Saving report & artifacts ====\")\n",
        "report_path = OUTPUT_DIR / \"rwsi_full_report.txt\"\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(\"\\n\".join(report_lines))\n",
        "write_report_line(f\"Report written to: {report_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "leHK_K5KmSkK",
        "outputId": "be65b2ae-8e32-4e7b-d9f8-e90eb5977417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results JSON saved to: rwsi_full_outputs/rwsi_results.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "with open(OUTPUT_DIR / \"rwsi_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "write_report_line(f\"Results JSON saved to: {OUTPUT_DIR / 'rwsi_results.json'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mHJdHf7MmUmY",
        "outputId": "7e7ba14b-52c9-4165-eaec-638777e2e2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Summary of trained models & key metrics ====\n",
            "Model: LogisticRegression\n",
            "  accuracy: 0.8787510137875101\n",
            "  precision_macro: 0.8110464051122082\n",
            "  recall_macro: 0.6599496538071168\n",
            "  f1_macro: 0.6993088868416899\n",
            "  roc_auc: None\n",
            "  cv_f1_macro: 0.7139921749531424\n",
            "  confusion_matrix: [[2036, 48], [251, 131]]\n",
            "Model: DecisionTree\n",
            "  accuracy: 0.7935928629359287\n",
            "  precision_macro: 0.6496782872253903\n",
            "  recall_macro: 0.7004288470621338\n",
            "  f1_macro: 0.6657745602419471\n",
            "  roc_auc: None\n",
            "  cv_f1_macro: 0.6704925855242673\n",
            "  confusion_matrix: [[1741, 343], [166, 216]]\n",
            "Model: RandomForest\n",
            "  accuracy: 0.8990267639902676\n",
            "  precision_macro: 0.8354445226366409\n",
            "  recall_macro: 0.7424983167690005\n",
            "  f1_macro: 0.7773486154135121\n",
            "  roc_auc: None\n",
            "  cv_f1_macro: 0.7871181839036276\n",
            "  confusion_matrix: [[2020, 64], [185, 197]]\n",
            "Model: NaiveBayes\n",
            "  accuracy: 0.7173560421735604\n",
            "  precision_macro: 0.626023834100465\n",
            "  recall_macro: 0.7194619187828482\n",
            "  f1_macro: 0.6263528335565547\n",
            "  roc_auc: None\n",
            "  cv_f1_macro: 0.6467863818642821\n",
            "  confusion_matrix: [[1493, 591], [106, 276]]\n",
            "Model: SVC\n",
            "  accuracy: 0.8450932684509327\n",
            "  precision_macro: 0.42254663422546634\n",
            "  recall_macro: 0.5\n",
            "  f1_macro: 0.458021978021978\n",
            "  roc_auc: None\n",
            "  cv_f1_macro: 0.4580596820910413\n",
            "  confusion_matrix: [[2084, 0], [382, 0]]\n",
            "Model: XGBoost\n",
            "  accuracy: 0.8884833738848338\n",
            "  precision_macro: 0.7948315774485382\n",
            "  recall_macro: 0.7522949724151099\n",
            "  f1_macro: 0.7708075422112586\n",
            "  roc_auc: None\n",
            "  cv_f1_macro: 0.7591576602256558\n",
            "  confusion_matrix: [[1979, 105], [170, 212]]\n",
            "\n",
            "All artifacts (models, report, results) saved to: rwsi_full_outputs\n",
            "If you want: I can (1) run class-balance experiments (SMOTE / class_weight), (2) hyperparameter tune RandomForest/XGBoost, or (3) produce plots (ROC/PR/feature distributions). Tell me which and I'll run it next.\n"
          ]
        }
      ],
      "source": [
        "write_report_line(\"\\n==== Summary of trained models & key metrics ====\")\n",
        "for m, info in results.items():\n",
        "    write_report_line(f\"Model: {m}\")\n",
        "    if isinstance(info, dict):\n",
        "        for k in [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"roc_auc\", \"cv_f1_macro\", \"cv_rmse_mean\", \"rmse\"]:\n",
        "            if k in info:\n",
        "                write_report_line(f\"  {k}: {info[k]}\")\n",
        "        if \"confusion_matrix\" in info:\n",
        "            write_report_line(f\"  confusion_matrix: {info['confusion_matrix']}\")\n",
        "    else:\n",
        "        write_report_line(f\"  info: {info}\")\n",
        "\n",
        "write_report_line(\"\\nAll artifacts (models, report, results) saved to: \" + str(OUTPUT_DIR))\n",
        "write_report_line(\"If you want: I can (1) run class-balance experiments (SMOTE / class_weight), (2) hyperparameter tune RandomForest/XGBoost, or (3) produce plots (ROC/PR/feature distributions). Tell me which and I'll run it next.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}